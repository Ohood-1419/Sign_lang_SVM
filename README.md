# Sign_lang_SVM
Recognition of sign language by using SVM

# Summary
This targets the Arabic numbers and alphabets sign recognition area based on fixed movement techniques by developing a vision-based model that provides sign language translation to text, allowing signers and non-signers to communicate more effectively. Applying SVM to classify the numbers and letters, then training the model, we got an accuracy of 76%.



# Technical description
1. Dataset  
The dataset contains images of 26 letters, and 10 numbers which is specifically all the Arabic letters, and numbers from 0-9. The dataset contains 469 images of sign language illustrating the letters and numbers which means we collected around 11 images for each letter and number.

2. SVM

the  training  and  classification  processes. It is a classification tool that has become extremely popular for image analysis in the recent past due to its relative simplicity and versatility in handling a variety of classification problems. SVMs uses machine learning idea to improve predictive accuracy while avoiding over-fitting to data, even in small sample size studies[4]. Because the proposed system includes 38 classes and each class requires a data set, and because of the difficulty of collecting all those large data sets, this method was chosen to correspond to the collected data set. 


<img width="468" alt="Picture1" src="https://user-images.githubusercontent.com/53026144/146065455-dfe0a5f2-a7a6-4ebe-89c0-ad4114cafdbc.png">

